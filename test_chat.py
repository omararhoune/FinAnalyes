# test_chat.py

import os
import google.generativeai as genai
from dotenv import load_dotenv

# Charger et configurer la clÃ© API (comme avant)
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
model = genai.GenerativeModel('gemini-1.5-flash')

# --- DÃ‰BUT DU CHANGEMENT ---

# 1. On commence une session de chat. C'est notre "mÃ©moire".
chat_session = model.start_chat(
    # (Optionnel) Vous pouvez donner une instruction de dÃ©part Ã  l'IA.
    history=[
        {
            "role": "user",
            "parts": ["Tu es FinAnalyse AI, un assistant financier expert. Tu rÃ©ponds aux questions sur la finance et l'investissement de maniÃ¨re simple et Ã©ducative. Ne donne jamais de conseil d'investissement direct."]
        },
        {
            "role": "model",
            "parts": ["Bonjour ! Je suis FinAnalyse AI. Comment puis-je vous aider Ã  mieux comprendre la finance aujourd'hui ?"]
        }
    ]
)

print("ğŸ¤– FinAnalyse AI: Bonjour ! Posez-moi une question sur la finance (tapez 'quitter' pour arrÃªter).")

# 2. On crÃ©e une boucle pour chatter en continu
while True:
    # On attend la question de l'utilisateur
    user_input = input("ğŸ‘¤ Vous: ")

    if user_input.lower() == 'quitter':
        print("ğŸ¤– FinAnalyse AI: Au revoir !")
        break

    # 3. On envoie le message Ã  la session de chat (pas directement au modÃ¨le)
    response = chat_session.send_message(user_input)

    # On affiche la rÃ©ponse de l'IA
    print(f"ğŸ¤– FinAnalyse AI: {response.text}")